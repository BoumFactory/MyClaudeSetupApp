#!/usr/bin/env python3
"""
Script de scission des PDFs de programmes officiels en pages individuelles.

Usage:
    python split_pdf_pages.py                    # Traite tous les PDFs
    python split_pdf_pages.py 2GT.pdf            # Traite un PDF sp√©cifique
    python split_pdf_pages.py --list             # Liste les PDFs disponibles
    python split_pdf_pages.py --status           # Affiche le statut des scissions
"""

import sys
import json
import io
from pathlib import Path
from datetime import datetime

# Forcer l'encodage UTF-8 pour la sortie console (Windows)
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')

# Import des biblioth√®ques PDF
from PyPDF2 import PdfReader, PdfWriter
import pdfplumber

# Chemins
SCRIPT_DIR = Path(__file__).parent
SKILL_DIR = SCRIPT_DIR.parent
PDF_DIR = SKILL_DIR / "pdf"
DATA_DIR = SKILL_DIR / "data"
PAGES_DIR = DATA_DIR / "pages"  # Dossier racine pour les pages


def ensure_directories():
    """Cr√©e les dossiers n√©cessaires."""
    DATA_DIR.mkdir(exist_ok=True)
    PAGES_DIR.mkdir(exist_ok=True)


def get_pdf_list() -> list[Path]:
    """Retourne la liste des PDFs disponibles."""
    return sorted(PDF_DIR.glob("*.pdf"))


def get_safe_folder_name(pdf_name: str) -> str:
    """G√©n√®re un nom de dossier s√ªr √† partir du nom du PDF."""
    # Enl√®ve l'extension et remplace les caract√®res sp√©ciaux
    name = pdf_name.replace(".pdf", "")
    name = name.replace(" ", "_")
    name = "".join(c if c.isalnum() or c in "_-" else "_" for c in name)
    return name


def split_single_pdf(pdf_path: Path, force: bool = False) -> dict:
    """
    Scinde un PDF en pages individuelles.

    Retourne un dictionnaire avec les m√©tadonn√©es de la scission.
    """
    folder_name = get_safe_folder_name(pdf_path.name)
    output_dir = PAGES_DIR / folder_name

    # V√©rifier si d√©j√† fait
    index_file = output_dir / "index.json"
    if index_file.exists() and not force:
        print(f"  [SKIP] {pdf_path.name} d√©j√† trait√© (utilisez --force pour retraiter)")
        with open(index_file, 'r', encoding='utf-8') as f:
            return json.load(f)

    print(f"\nüìÑ Traitement de {pdf_path.name}...")

    # Cr√©er le dossier de sortie
    output_dir.mkdir(exist_ok=True)

    # Ouvrir le PDF avec PyPDF2 pour la scission
    reader = PdfReader(str(pdf_path))
    total_pages = len(reader.pages)
    print(f"   -> {total_pages} pages d√©tect√©es")

    # Pr√©parer les m√©tadonn√©es
    result = {
        "source_pdf": pdf_path.name,
        "folder_name": folder_name,
        "total_pages": total_pages,
        "extraction_date": datetime.now().isoformat(),
        "pages": []
    }

    # Extraire chaque page
    for page_num in range(total_pages):
        page_index = page_num + 1  # Num√©rotation 1-based
        page_filename = f"page_{page_index:03d}.pdf"
        page_path = output_dir / page_filename

        # Cr√©er un PDF pour cette page uniquement
        writer = PdfWriter()
        writer.add_page(reader.pages[page_num])

        with open(page_path, 'wb') as output_file:
            writer.write(output_file)

        # Extraire le texte de la page pour l'index
        page_text = ""
        try:
            with pdfplumber.open(pdf_path) as pdf:
                if page_num < len(pdf.pages):
                    page_text = pdf.pages[page_num].extract_text() or ""
        except Exception as e:
            page_text = f"[Erreur extraction: {e}]"

        # R√©sum√© court du contenu (premiers 500 caract√®res)
        text_preview = page_text[:500].replace("\n", " ").strip()
        if len(page_text) > 500:
            text_preview += "..."

        # D√©tecter les sections/th√®mes potentiels
        detected_themes = detect_themes(page_text)

        page_info = {
            "page_number": page_index,
            "filename": page_filename,
            "text_length": len(page_text),
            "preview": text_preview,
            "detected_themes": detected_themes,
            "status": "pending"  # Pour le traitement par agent
        }

        result["pages"].append(page_info)

        # Sauvegarder aussi le texte brut
        txt_filename = f"page_{page_index:03d}.txt"
        txt_path = output_dir / txt_filename
        with open(txt_path, 'w', encoding='utf-8') as f:
            f.write(page_text)

        print(f"   ‚úì Page {page_index}/{total_pages}", end="\r")

    print(f"   ‚úì {total_pages} pages extraites            ")

    # Sauvegarder l'index
    with open(index_file, 'w', encoding='utf-8') as f:
        json.dump(result, f, ensure_ascii=False, indent=2)

    print(f"   ‚úì Index sauvegard√©: {index_file.name}")

    return result


def detect_themes(text: str) -> list[str]:
    """
    D√©tecte les th√®mes math√©matiques pr√©sents dans le texte.
    Retourne une liste de th√®mes identifi√©s.
    """
    themes_keywords = {
        "nombres": ["nombre", "entier", "d√©cimal", "fraction", "rationnel", "r√©el", "calcul", "op√©ration"],
        "alg√®bre": ["alg√®bre", "expression", "√©quation", "in√©quation", "fonction", "variable", "polyn√¥me", "factorisation"],
        "g√©om√©trie": ["g√©om√©trie", "figure", "triangle", "cercle", "droite", "angle", "vecteur", "coordonn√©e", "rep√®re"],
        "analyse": ["limite", "d√©riv√©e", "primitive", "int√©grale", "continuit√©", "suite", "convergence", "exponentielle", "logarithme"],
        "probabilit√©s": ["probabilit√©", "√©v√©nement", "al√©atoire", "variable al√©atoire", "esp√©rance", "variance", "loi"],
        "statistiques": ["statistique", "moyenne", "m√©diane", "√©cart-type", "effectif", "fr√©quence", "diagramme"],
        "algorithmique": ["algorithme", "programme", "python", "boucle", "condition", "fonction", "instruction"],
        "trigonom√©trie": ["trigonom√©trie", "cosinus", "sinus", "tangente", "radian", "cercle trigonom√©trique"],
        "grandeurs": ["grandeur", "mesure", "unit√©", "conversion", "proportionnalit√©", "pourcentage", "vitesse"],
        "logique": ["logique", "d√©monstration", "raisonnement", "implication", "√©quivalence", "r√©ciproque", "contrapos√©e"]
    }

    text_lower = text.lower()
    detected = []

    for theme, keywords in themes_keywords.items():
        if any(kw in text_lower for kw in keywords):
            detected.append(theme)

    return detected


def process_all_pdfs(force: bool = False) -> dict:
    """Traite tous les PDFs disponibles."""
    ensure_directories()

    pdf_files = get_pdf_list()
    print(f"üìö {len(pdf_files)} PDFs trouv√©s dans {PDF_DIR}\n")

    results = {
        "processed_date": datetime.now().isoformat(),
        "total_pdfs": len(pdf_files),
        "pdfs": []
    }

    for pdf_path in pdf_files:
        result = split_single_pdf(pdf_path, force=force)
        results["pdfs"].append({
            "name": pdf_path.name,
            "folder": result.get("folder_name", ""),
            "pages": result.get("total_pages", 0)
        })

    # Sauvegarder le r√©sum√© global
    summary_file = DATA_DIR / "split_summary.json"
    with open(summary_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)

    print(f"\n‚úÖ R√©sum√© global sauvegard√©: {summary_file}")
    return results


def show_status():
    """Affiche le statut des scissions."""
    print("üìä Statut des scissions PDF\n")

    pdf_files = get_pdf_list()

    for pdf_path in pdf_files:
        folder_name = get_safe_folder_name(pdf_path.name)
        output_dir = PAGES_DIR / folder_name
        index_file = output_dir / "index.json"

        if index_file.exists():
            with open(index_file, 'r', encoding='utf-8') as f:
                data = json.load(f)

            pages_done = len([p for p in data.get("pages", []) if p.get("status") == "processed"])
            total = data.get("total_pages", 0)
            status = "‚úÖ" if pages_done == total else f"‚è≥ {pages_done}/{total}"
        else:
            status = "‚ùå Non trait√©"

        print(f"  {pdf_path.name:40} {status}")


def list_pdfs():
    """Liste les PDFs disponibles."""
    print("üìö PDFs disponibles:\n")
    for pdf_path in get_pdf_list():
        size = pdf_path.stat().st_size / 1024  # KB
        print(f"  ‚Ä¢ {pdf_path.name:40} ({size:.1f} KB)")


def main():
    """Point d'entr√©e principal."""
    args = sys.argv[1:]

    if "--help" in args or "-h" in args:
        print(__doc__)
        return

    if "--list" in args:
        list_pdfs()
        return

    if "--status" in args:
        show_status()
        return

    force = "--force" in args
    if force:
        args.remove("--force")

    ensure_directories()

    if args:
        # Traiter un PDF sp√©cifique
        pdf_name = args[0]
        pdf_path = PDF_DIR / pdf_name

        if not pdf_path.exists():
            print(f"‚ùå PDF non trouv√©: {pdf_path}")
            print("\nPDFs disponibles:")
            list_pdfs()
            return

        split_single_pdf(pdf_path, force=force)
    else:
        # Traiter tous les PDFs
        results = process_all_pdfs(force=force)

        print("\n" + "="*50)
        print("üìä R√âSUM√â")
        print("="*50)
        total_pages = sum(p["pages"] for p in results["pdfs"])
        print(f"  ‚Ä¢ PDFs trait√©s: {results['total_pdfs']}")
        print(f"  ‚Ä¢ Pages totales: {total_pages}")
        print(f"  ‚Ä¢ Dossier de sortie: {PAGES_DIR}")


if __name__ == "__main__":
    main()
